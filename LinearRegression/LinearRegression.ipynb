{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNv6VDnM6ZTtA+Ux82UBNfI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2JH8AvOIoTND","executionInfo":{"status":"ok","timestamp":1739461916062,"user_tz":-300,"elapsed":27489,"user":{"displayName":"Danish Ali","userId":"17532472304470261445"}},"outputId":"79fdb450-8699-4e84-a8e3-4742407c4391"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"markdown","source":["# Table of Contents\n","\n","## Introduction\n","\n","## What is Linear Regression?\n","- Importance and Applications\n","\n","## Mathematical Foundation\n","- The Linear Regression Equation\n","- Cost Function (Mean Squared Error - MSE)\n","- Optimization using Gradient Descent\n","- Analytical Solution: Normal Equation\n","\n","## Dataset Preparation\n","- Selecting a Dataset (e.g., Synthetic Data or Real-world Data)\n","- Data Preprocessing (Handling Missing Values, Normalization, etc.)\n","- Splitting Data into Training and Testing Sets\n","\n","## Implementation from Scratch\n","- Implementing Linear Regression using NumPy\n","- Computing Cost Function\n","- Implementing Gradient Descent\n","- Making Predictions\n","\n","## Implementation using Scikit-Learn\n","- Using `LinearRegression` from `sklearn`\n","- Training the Model\n","- Evaluating Model Performance\n","\n","## Model Evaluation Metrics\n","- Mean Squared Error (MSE)\n","- Mean Absolute Error (MAE)\n","- RÂ² Score\n","\n","## Visualizing Results\n","- Plotting Regression Line on Training Data\n","- Residual Analysis\n","\n","## Regularization Techniques (Optional)\n","- Ridge Regression (L2 Regularization)\n","- Lasso Regression (L1 Regularization)\n","\n","## Comparison of Approaches\n","- Gradient Descent vs. Normal Equation\n","- When to Use Each Method\n","\n","## Conclusion & Future Scope\n","- Summary of Key Learnings\n","- Possible Enhancements (Polynomial Regression, Multiple Linear Regression)\n"],"metadata":{"id":"NXseTo7Qlztv"}},{"cell_type":"markdown","source":["## What is Linear Regression?\n","\n","Linear Regression is a fundamental statistical and machine learning technique used to model the relationship between a dependent variable and one or more independent variables. It assumes a linear relationship between input features and the target variable. The goal is to find the best-fitting straight line that minimizes the difference between the actual and predicted values.\n","\n","### Importance and Applications\n","\n","- **Predictive Modeling**: Used for forecasting and trend analysis, such as predicting house prices or sales revenue.\n","- **Interpretability**: Provides a clear understanding of the impact of each feature on the target variable.\n","- **Foundation for Advanced Models**: Serves as a building block for more complex regression techniques and machine learning algorithms.\n","- **Ease of Implementation**: Computationally efficient and easy to implement using various tools like NumPy and Scikit-Learn.\n"],"metadata":{"id":"AJkUf4N4mMtB"}},{"cell_type":"markdown","source":["## Mathematical Foundation\n","\n","Linear Regression is based on a strong mathematical foundation that defines how a model learns and makes predictions. This section covers the key mathematical components.\n","\n","### The Linear Regression Equation\n","\n","The fundamental equation for simple linear regression is:\n","\n","$$\n","y = mx + b\n","$$\n","\n","For multiple linear regression:\n","\n","$$\n","y = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... + \\theta_n x_n\n","$$\n","\n","where:\n","- $y$ is the predicted output.\n","- $x_i$ are the input features ($i$th feature of the dataset).\n","- $Î¸_i$ are the model parameters (weights associated with each feature).\n","- $Î¸_0$ is the bias term (intercept).\n","\n","### Cost Function (Mean Squared Error - MSE)\n","\n","To measure how well our model fits the data, we use the **Mean Squared Error (MSE)**:\n","\n","$$\n","MSE = \\frac{1}{m} \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2\n","$$\n","\n","where:\n","- m is the number of training examples.\n","- $y_i$ is the actual value of the $i$th sample.\n","- $\\hat{y}_i$ is the predicted value of the $i$th sample.\n","\n","The goal is to minimize this cost function to improve model accuracy.\n","\n","### Optimization using Gradient Descent\n","\n","Gradient Descent is an optimization algorithm used to minimize the cost function by updating model parameters iteratively:\n","\n","$$\n","\\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j}\n","$$\n","\n","where:\n","- Î± is the learning rate (step size in parameter updates).\n","- J(Î¸) is the cost function.\n","\n","Gradient Descent ensures that we converge towards the optimal values of `$Î¸$`.\n","\n","### Analytical Solution: Normal Equation\n","\n","Instead of using Gradient Descent, we can directly compute the optimal parameters using the **Normal Equation**:\n","\n","$$\n","\\theta = (X^T X)^{-1} X^T y\n","$$\n","\n","where:\n","- X is the matrix of input features.\n","- y is the output vector.\n","\n","This method is computationally efficient for small datasets but may be slow for large datasets due to matrix inversion.\n"],"metadata":{"id":"ZxfFVHcAoHy9"}},{"cell_type":"markdown","source":["### Import Neccessary Libraries\n"],"metadata":{"id":"jCWZc5HRmOss"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np"],"metadata":{"id":"S12bXbd7obLD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Lost DataSet"],"metadata":{"id":"ZygnpTDumTcz"}},{"cell_type":"code","source":["data = pd.read_csv('gdrive/My Drive/Datasets/data_for_LR.csv')\n","data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"EAEpW1DiogBZ","executionInfo":{"status":"ok","timestamp":1739463907848,"user_tz":-300,"elapsed":14,"user":{"displayName":"Danish Ali","userId":"17532472304470261445"}},"outputId":"d8619d61-ae14-4814-ceba-5e1ecbfed135"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        x          y\n","0    24.0  21.549452\n","1    50.0  47.464463\n","2    15.0  17.218656\n","3    38.0  36.586398\n","4    87.0  87.288984\n","..    ...        ...\n","695  58.0  58.595006\n","696  93.0        NaN\n","697  82.0  88.603770\n","698  66.0  63.648685\n","699  97.0  94.975266\n","\n","[700 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-824de96f-ccbb-46b3-9139-c148b87e1a71\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>x</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>24.0</td>\n","      <td>21.549452</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50.0</td>\n","      <td>47.464463</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>15.0</td>\n","      <td>17.218656</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>38.0</td>\n","      <td>36.586398</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>87.0</td>\n","      <td>87.288984</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>695</th>\n","      <td>58.0</td>\n","      <td>58.595006</td>\n","    </tr>\n","    <tr>\n","      <th>696</th>\n","      <td>93.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>697</th>\n","      <td>82.0</td>\n","      <td>88.603770</td>\n","    </tr>\n","    <tr>\n","      <th>698</th>\n","      <td>66.0</td>\n","      <td>63.648685</td>\n","    </tr>\n","    <tr>\n","      <th>699</th>\n","      <td>97.0</td>\n","      <td>94.975266</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>700 rows Ã— 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-824de96f-ccbb-46b3-9139-c148b87e1a71')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-824de96f-ccbb-46b3-9139-c148b87e1a71 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-824de96f-ccbb-46b3-9139-c148b87e1a71');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2230a1b6-84c7-4655-bce9-d6c98c39ed02\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2230a1b6-84c7-4655-bce9-d6c98c39ed02')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2230a1b6-84c7-4655-bce9-d6c98c39ed02 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_9bb3662c-a22e-4bf6-9208-fc52c1ea1aaf\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_9bb3662c-a22e-4bf6-9208-fc52c1ea1aaf button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('data');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data","summary":"{\n  \"name\": \"data\",\n  \"rows\": 700,\n  \"fields\": [\n    {\n      \"column\": \"x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 134.86298244029686,\n        \"min\": 0.0,\n        \"max\": 3530.157369,\n        \"num_unique_values\": 102,\n        \"samples\": [\n          21.0,\n          45.0,\n          56.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29.116888623753933,\n        \"min\": -3.83998112,\n        \"max\": 108.8716183,\n        \"num_unique_values\": 690,\n        \"samples\": [\n          94.70291077,\n          74.29662112,\n          49.92639685\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["data.dropna(inplace=True)\n","data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"wJt3k1O5sf1b","executionInfo":{"status":"ok","timestamp":1739463909117,"user_tz":-300,"elapsed":9,"user":{"displayName":"Danish Ali","userId":"17532472304470261445"}},"outputId":"9e2ac859-b1b4-4570-e4bc-d4e944b2ec65"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        x          y\n","0    24.0  21.549452\n","1    50.0  47.464463\n","2    15.0  17.218656\n","3    38.0  36.586398\n","4    87.0  87.288984\n","..    ...        ...\n","694  81.0  81.455447\n","695  58.0  58.595006\n","697  82.0  88.603770\n","698  66.0  63.648685\n","699  97.0  94.975266\n","\n","[689 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-60798c3d-8c06-4e62-ba4e-a5b2bd7532a4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>x</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>24.0</td>\n","      <td>21.549452</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50.0</td>\n","      <td>47.464463</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>15.0</td>\n","      <td>17.218656</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>38.0</td>\n","      <td>36.586398</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>87.0</td>\n","      <td>87.288984</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>694</th>\n","      <td>81.0</td>\n","      <td>81.455447</td>\n","    </tr>\n","    <tr>\n","      <th>695</th>\n","      <td>58.0</td>\n","      <td>58.595006</td>\n","    </tr>\n","    <tr>\n","      <th>697</th>\n","      <td>82.0</td>\n","      <td>88.603770</td>\n","    </tr>\n","    <tr>\n","      <th>698</th>\n","      <td>66.0</td>\n","      <td>63.648685</td>\n","    </tr>\n","    <tr>\n","      <th>699</th>\n","      <td>97.0</td>\n","      <td>94.975266</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>689 rows Ã— 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60798c3d-8c06-4e62-ba4e-a5b2bd7532a4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-60798c3d-8c06-4e62-ba4e-a5b2bd7532a4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-60798c3d-8c06-4e62-ba4e-a5b2bd7532a4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-10143f26-7422-4a96-beb1-5397805f1b87\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-10143f26-7422-4a96-beb1-5397805f1b87')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-10143f26-7422-4a96-beb1-5397805f1b87 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_f7cdf5e2-be32-4bb8-925f-5a66b66bd4a7\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_f7cdf5e2-be32-4bb8-925f-5a66b66bd4a7 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('data');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data","summary":"{\n  \"name\": \"data\",\n  \"rows\": 689,\n  \"fields\": [\n    {\n      \"column\": \"x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28.91338529455891,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 101,\n        \"samples\": [\n          78.0,\n          35.0,\n          70.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29.070020581629358,\n        \"min\": -3.83998112,\n        \"max\": 108.8716183,\n        \"num_unique_values\": 688,\n        \"samples\": [\n          94.70291077,\n          6.709195759,\n          49.92639685\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["X = np.array(data.iloc[:,:-1])\n","Y = np.array(data.iloc[:,-1])"],"metadata":{"id":"kZKlmujapFVi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def splitData(X,Y,testPercentage= 0.2):\n","      trainPercentage = 1 - testPercentage\n","      Xtrain = []\n","      Ytrain = []\n","      Xtest = []\n","      Ytest = []\n","\n","      # labels , counts  = np.unique(Y,return_counts=True)\n","      # # print(labels,counts)\n","\n","      # for i in range(len(labels)):\n","      #   indices = np.where(Y == labels[i])\n","      #   Xt = X[indices]\n","      #   Yt = Y[indices]\n","      #   # print(Xt)\n","        # print(Yt)\n","      randomArray = np.arange(0,len(X))\n","      np.random.shuffle(randomArray)\n","      # print(randomArray)\n","      # print(round(trainPercentage * counts[i]))\n","      Xtrain_indices_After_shuffling = randomArray[0:(round(trainPercentage * len(X)))]\n","      Xtest_indices_After_shuffling = randomArray[(round(trainPercentage * len(X))): ]\n","      Xtrain_shuffle = X[Xtrain_indices_After_shuffling]\n","      Xtest_shuffle =  X[Xtest_indices_After_shuffling]\n","\n","      Xtrain.extend(Xtrain_shuffle)\n","      Ytrain.extend(Y[Xtrain_indices_After_shuffling])\n","      Xtest.extend(Xtest_shuffle)\n","      Ytest.extend(Y[Xtest_indices_After_shuffling])\n","\n","\n","      Xtrain = np.array(Xtrain)\n","      Ytrain = np.array(Ytrain)\n","      Xtest = np.array(Xtest)\n","      Ytest = np.array(Ytest)\n","\n","      return Xtrain,Ytrain,Xtest,Ytest\n"],"metadata":{"id":"wfqmK4yLpp1Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to split the dataset\n","Xtrain,Ytrain,Xtest,Ytest = splitData(X,Y)\n","print (\" Training Data Set Dimensions=\", Xtrain.shape, \"Training True Class labels dimensions\", Ytrain.shape)\n","print (\" Test Data Set Dimensions=\", Xtest.shape, \"Test True Class labels dimensions\", Ytest.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nI6NqC8Gpz8H","executionInfo":{"status":"ok","timestamp":1739466396004,"user_tz":-300,"elapsed":5,"user":{"displayName":"Danish Ali","userId":"17532472304470261445"}},"outputId":"c3306a14-0be1-4208-eef3-24572269788f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Training Data Set Dimensions= (551, 1) Training True Class labels dimensions (551,)\n"," Test Data Set Dimensions= (138, 1) Test True Class labels dimensions (138,)\n"]}]},{"cell_type":"markdown","source":["# **Gradient Descent for Linear Regression**\n","\n","A **Linear Regression** model can be trained using **Gradient Descent**, an optimization algorithm that iteratively updates the modelâ€™s parameters to reduce the **Mean Squared Error (MSE)**. The goal is to update ( $ \\theta_1 \\ $) and ( $\\theta_2 \\ $) to minimize the cost function and achieve the best-fit line.\n","\n","The idea is:\n","1. Start with random values of ( $ \\theta_1 \\ $) and ( $ \\theta_2 \\ $).\n","2. Iteratively update these values to reach the minimum cost.\n","\n","## **Gradient and Derivatives**\n","A **gradient** is the derivative of a function that tells us how outputs change with a small change in inputs.\n","\n","### **Computing Partial Derivatives of Cost Function**\n","The cost function is:\n","\n","$$\n","J(\\theta_1, \\theta_2) = \\frac{1}{n} \\sum_{i=1}^{n} ( \\hat{y}_i - y_i )^2\n","$$\n","\n","#### **Derivative w.r.t. \\( $\\theta_1 \\$)**\n","\n","$$\n","J'_{\\theta_1} = \\frac{\\partial J(\\theta_1, \\theta_2)}{\\partial \\theta_1}\n","$$\n","\n","$$\n","= \\frac{\\partial}{\\partial \\theta_1} \\left[ \\frac{1}{n} \\sum_{i=1}^{n} ( \\hat{y}_i - y_i )^2 \\right]\n","$$\n","\n","$$\n","= \\frac{1}{n} \\sum_{i=1}^{n} 2( \\hat{y}_i - y_i ) \\frac{\\partial}{\\partial \\theta_1} ( \\theta_1 + \\theta_2 x_i - y_i )\n","$$\n","\n","$$\n","= \\frac{1}{n} \\sum_{i=1}^{n} 2( \\hat{y}_i - y_i ) (1)\n","$$\n","\n","$$\n","= \\frac{2}{n} \\sum_{i=1}^{n} ( \\hat{y}_i - y_i )\n","$$\n","\n","#### **Derivative w.r.t. ($\\theta_2 \\$)**\n","\n","$$\n","J'_{\\theta_2} = \\frac{\\partial J(\\theta_1, \\theta_2)}{\\partial \\theta_2}\n","$$\n","\n","$$\n","= \\frac{\\partial}{\\partial \\theta_2} \\left[ \\frac{1}{n} \\sum_{i=1}^{n} ( \\hat{y}_i - y_i )^2 \\right]\n","$$\n","\n","$$\n","= \\frac{1}{n} \\sum_{i=1}^{n} 2( \\hat{y}_i - y_i ) \\frac{\\partial}{\\partial \\theta_2} ( \\theta_1 + \\theta_2 x_i - y_i )\n","$$\n","\n","$$\n","= \\frac{1}{n} \\sum_{i=1}^{n} 2( \\hat{y}_i - y_i ) x_i\n","$$\n","\n","$$\n","= \\frac{2}{n} \\sum_{i=1}^{n} ( \\hat{y}_i - y_i ) \\cdot x_i\n","$$\n","\n","---\n","\n","## **Updating Parameters Using Gradient Descent**\n","The objective of **Linear Regression** is to find the best coefficients. We update parameters by taking steps in the **negative direction** of the gradient:\n","\n","$$\n","\\theta_1 = \\theta_1 - \\alpha \\cdot J'_{\\theta_1}\n","$$\n","\n","$$\n","= \\theta_1 - \\alpha \\cdot \\frac{2}{n} \\sum_{i=1}^{n} ( \\hat{y}_i - y_i )\n","$$\n","\n","$$\n","\\theta_2 = \\theta_2 - \\alpha \\cdot J'_{\\theta_2}\n","$$\n","\n","$$\n","= \\theta_2 - \\alpha \\cdot \\frac{2}{n} \\sum_{i=1}^{n} ( \\hat{y}_i - y_i ) \\cdot x_i\n","$$\n","\n","where:\n","- \\( $\\alpha\\$) is the **learning rate** that determines step size.\n","\n","---\n","\n","### **Conclusion**\n","- **Gradient Descent** helps find the optimal values of ($ \\theta_1\\ $) and\n","($ \\theta_2\\ $).\n","- We move in the **negative gradient direction** to minimize the cost function.\n","- The choice of **learning rate** (\\($ \\alpha \\ $)) affects convergence speed.\n","\n","This is the core idea of **Gradient Descent in Linear Regression**! ðŸš€\n"],"metadata":{"id":"Ezb4yq-rqHFN"}},{"cell_type":"code","source":["\n","\n","class LinearRegression:\n","    \"\"\"\n","    A simple implementation of Linear Regression using Gradient Descent with optional Regularization.\n","\n","    Attributes:\n","        epochs (int): Number of iterations for gradient descent.\n","        lr (float): Learning rate.\n","        lambda_ (float): Regularization strength.\n","        loss (str): Type of loss function (\"ridge\" for L2, \"lasso\" for L1, or None for normal MSE).\n","        weights (np.ndarray): Model coefficients.\n","        bias (float): Model bias term.\n","    \"\"\"\n","\n","    def __init__(self, epochs=500, lr=0.01, lambda_=0.1, loss=None):\n","        \"\"\"\n","        Initializes the Linear Regression model.\n","\n","        Args:\n","            epochs (int): Number of training iterations.\n","            lr (float): Learning rate.\n","            lambda_ (float): Regularization strength.\n","            loss (str): \"ridge\" for Ridge Regression, \"lasso\" for Lasso Regression, or None for normal MSE.\n","        \"\"\"\n","        self.epochs = epochs\n","        self.lr = lr\n","        self.lambda_ = lambda_\n","        self.loss = loss\n","        self.weights = None\n","        self.bias = None\n","        self.nexamples = None\n","\n","    def hypothesis(self):\n","        \"\"\"\n","        Computes predictions using the current weights and bias.\n","\n","        Returns:\n","            np.ndarray: Predicted values.\n","        \"\"\"\n","        return np.dot(self.X, self.weights) + self.bias\n","\n","    def loss_function(self):\n","        \"\"\"\n","        Computes Mean Squared Error (MSE) loss with optional regularization.\n","\n","        Returns:\n","            float: The computed loss value.\n","        \"\"\"\n","        y_pred = self.hypothesis().reshape(self.nexamples,1)\n","        loss = np.mean((self.Y - y_pred) ** 2)\n","\n","        if self.loss == \"ridge\":\n","            return loss + self.Ridge_Regression()\n","        elif self.loss == \"lasso\":\n","            return loss + self.Lasso_Regression()\n","        return loss  # No regularization\n","\n","    def gradient_descent(self):\n","        \"\"\"\n","        Computes the gradients for weights and bias.\n","\n","        Returns:\n","            tuple: Gradients for weights and bias.\n","        \"\"\"\n","        y_pred = self.hypothesis().reshape(self.nexamples,1)\n","        error = (self.Y - y_pred)\n","        print(\"error shape : \",error.shape)\n","        print(\"After error * self.X  Shape : \",(self.X).shape)\n","        new_thetas = -2 / self.nexamples * np.sum(error * self.X, axis=0)\n","        new_bias = -np.mean(error)\n","\n","        return new_thetas, new_bias\n","\n","    def Ridge_Regression(self):\n","        \"\"\"\n","        Computes L2 (Ridge) Regularization loss.\n","\n","        Returns:\n","            float: L2 regularization loss.\n","        \"\"\"\n","        return self.lambda_ * np.sum(self.weights ** 2)\n","\n","    def Lasso_Regression(self):\n","        \"\"\"\n","        Computes L1 (Lasso) Regularization loss.\n","\n","        Returns:\n","            float: L1 regularization loss.\n","        \"\"\"\n","        return self.lambda_ * np.sum(abs(self.weights))\n","\n","    def train(self, X, Y):\n","        \"\"\"\n","        Trains the model using Gradient Descent.\n","\n","        Args:\n","            X (np.ndarray): Training features (num_samples, num_features).\n","            Y (np.ndarray): Target values (num_samples,).\n","        \"\"\"\n","        X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n","        self.nexamples, nfeatures = X.shape\n","        self.weights = np.zeros(nfeatures)\n","        self.bias = 0\n","        self.X = X\n","        self.Y = Y.reshape(self.nexamples,1)\n","        print(self.X.shape ,\"     \",self.Y.shape)\n","        prev_loss = float('inf')\n","        tol = 1e-3\n","        losses = []\n","        for epoch in range(self.epochs):\n","            new_thetas, new_bias = self.gradient_descent()\n","\n","            # Update weights based on regularization type\n","            if self.loss == \"ridge\":\n","                self.weights -= self.lr * (new_thetas + (2 * self.lambda_ * self.weights))  # L2 Regularization\n","            elif self.loss == \"lasso\":\n","                self.weights -= self.lr * (new_thetas + (self.lambda_ * np.sign(self.weights)))  # L1 Regularization\n","            else:\n","                self.weights -= self.lr * new_thetas  # No Regularization\n","\n","            # Bias is updated normally (no regularization)\n","            self.bias -= self.lr * new_bias\n","\n","            loss = self.loss_function()\n","            losses.append(loss)\n","            print(\"Loss : \",loss)\n","            # Early stopping\n","            # if abs(prev_loss - loss) < tol:\n","            #     print(f\"Early stopping at epoch {epoch+1}\")\n","            #     break\n","\n","            # prev_loss = loss\n","\n","    def normalize_features(self, X):\n","        \"\"\"\n","        Standardizes the features using mean and standard deviation.\n","        Args:\n","            X (np.ndarray): Input features.\n","        Returns:\n","            np.ndarray: Normalized features.\n","        \"\"\"\n","        return (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n","\n","    def r2_score(self, Y_true, Y_pred):\n","        \"\"\"\n","        Computes the R-squared (coefficient of determination) score.\n","        Args:\n","            Y_true (np.ndarray): Actual values.\n","            Y_pred (np.ndarray): Predicted values.\n","        Returns:\n","            float: RÂ² score.\n","        \"\"\"\n","        ss_total = np.sum((Y_true - np.mean(Y_true)) ** 2)\n","        ss_residual = np.sum((Y_true - Y_pred) ** 2)\n","        return 1 - (ss_residual / ss_total)\n","    def plot_learning_curve(self, losses):\n","        \"\"\"\n","        Plots the training loss over epochs.\n","        Args:\n","            losses (list): Loss values recorded over iterations.\n","        \"\"\"\n","        import matplotlib.pyplot as plt\n","        plt.plot(range(len(losses)), losses, label=\"Training Loss\")\n","        plt.xlabel(\"Epochs\")\n","        plt.ylabel(\"Loss\")\n","        plt.title(\"Learning Curve\")\n","        plt.legend()\n","        plt.show()\n","\n","    def get_params(self):\n","        \"\"\"\n","        Returns the model parameters (weights & bias).\n","        \"\"\"\n","        return {\"weights\": self.weights, \"bias\": self.bias}\n","\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Predicts output values for given input features.\n","\n","        Args:\n","            X (np.ndarray): Input features for prediction.\n","\n","        Returns:\n","            np.ndarray: Predicted values.\n","        \"\"\"\n","        return np.dot(X, self.weights) + self.bias\n"],"metadata":{"id":"LgA83kua7cjv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OVQTpAbwp8K5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LR = LinearRegression(epochs = 500,lr=0.01)\n","LR.train(Xtrain,Ytrain)\n","LR.loss_function()\n","LR.get_params()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bbEXdpXjq3Q1","executionInfo":{"status":"ok","timestamp":1739470595129,"user_tz":-300,"elapsed":336,"user":{"displayName":"Danish Ali","userId":"17532472304470261445"}},"outputId":"6e35489a-e0a6-42e4-8565-1e51daef02ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(551, 1)       (551, 1)\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  3213.5913968620152\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  3133.9424853878113\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  3056.5064198344353\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  2981.2143023977937\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  2907.999590882041\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  2836.798012835108\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  2767.5474829368636\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  2700.188023514024\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  2634.661688060885\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  2570.912487649652\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  2508.886320118723\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  2448.5309019316105\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  2389.7957026034196\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  2332.631881595792\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  2276.992227585134\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  2222.831100012631\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  2170.104372828161\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  2118.769380343607\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  2068.784865114415\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  2020.1109277713683\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1972.708978727623\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1926.5416916889535\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1881.5729588979834\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1837.767848045852\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1795.0925607873864\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1753.5143927983202\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1713.0016953154952\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1673.5238381032916\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1635.0511737917325\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1597.5550035338265\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1561.007543931766\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1525.3818951835374\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1490.652010403403\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1456.7926660715004\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1423.7794335695626\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1391.5886517614138\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1360.1974005785137\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1329.5834755723567\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1299.7253633970086\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1270.6022181864985\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1242.1938387931364\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1214.4806468541542\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1187.4436656553135\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1161.0644997613515\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1135.3253153842913\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1110.208821461769\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1085.6982514185959\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1061.7773455858214\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1038.4303342525432\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  1015.6419213266744\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  993.3972685817852\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  971.6819804680285\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  950.482089466002\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  929.7840419632023\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  909.5746846335311\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  889.8412513010411\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  870.57135026985\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  851.7529521028341\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  833.3743778323836\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  815.4242875871442\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  797.8916696192839\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  780.7658297174157\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  764.0363809908762\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  747.6932340116099\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  731.7265873004284\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  716.1269181449262\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  700.8849737368146\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  685.9917626169052\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  671.4385464164211\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  657.2168318837479\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  643.3183631861452\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  629.7351144763467\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  616.4592827143505\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  603.4832807350756\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  590.7997305529119\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  578.401456894531\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  566.2814809516532\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  554.43301434578\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  542.8494532972014\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  531.524372990883\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  520.4515221321086\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  509.624817685034\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  499.0383397875538\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  488.6863268361396\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  478.563170734543\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  468.66341230048585\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  458.98173682468394\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  449.5129697767574\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  440.25207265278976\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  431.1941389594897\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  422.3343903301024\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  413.6681727673922\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  405.1909530092022\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  396.89831501225126\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  388.7859565500041\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  380.84968592059283\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  373.0854187609264\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  365.48917496326175\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  358.0570756906523\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  350.7853404878193\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  343.6702844841224\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  336.70831568542184\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  329.8959323517536\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  323.2297204578404\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  316.7063512335791\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  310.3225787817461\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  304.07523777026546\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  297.9612411964795\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  291.97757822095565\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  286.12131206845754\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  280.3895779937863\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  274.77958131029015\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  269.28859547891415\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  263.9139602557437\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  258.65307989606515\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  253.5034214130422\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  248.46251288917207\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  243.52794183875662\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  238.69735361967807\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  233.9684498928425\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  229.3389871277018\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  224.80677515232784\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  220.36967574656708\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  216.02560127685243\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  211.77251337130514\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  207.608421633802\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  203.53138239573767\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  199.53949750424852\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  195.63091314571426\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  191.80381870339409\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  188.05644564809106\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  184.387066460782\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  180.79399358618375\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  177.2755784162648\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  173.83021030274486\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  170.45631559765872\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  167.15235672109267\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  163.91683125523323\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  160.74827106389657\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  157.64524143673646\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  154.60634025735766\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  151.63019719458455\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  148.7154729161645\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  145.86085832420775\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  143.06507381169007\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  140.32686853936784\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  137.64501973247673\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  135.01833199660638\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  132.44563665216484\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  129.9257910868655\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  127.45767812568846\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  125.04020541778792\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  122.67230483983171\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  120.352931915281\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  118.08106524912961\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  115.85570597764224\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  113.67587723264387\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  111.54062361992881\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  109.44901071137028\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  107.40012455032809\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  105.39307116996133\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  103.42697612407032\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  101.50098403009953\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  99.61425812394964\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  97.76597982625515\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  95.95534831979597\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  94.18158013772326\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  92.44390876228839\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  90.74158423377474\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  89.07387276934107\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  87.44005639149609\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  85.83943256593028\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  84.27131384844138\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  82.7350275406982\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  81.22991535459518\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  79.7553330849565\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  78.31065029035987\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  76.89524998185189\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  75.50852831933985\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  74.14989431544605\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  72.81876954662165\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  71.5145878713205\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  70.23679515504072\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  68.9848490020479\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  67.75821849359869\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  66.55638393248915\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  65.37883659375841\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  64.22507848138248\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  63.094622090798026\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  61.9869901771014\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  60.90171552877174\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  59.838340746773035\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  58.7964180288925\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  57.775508959178204\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  56.775184302342915\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  55.7950238030036\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  54.83461598963187\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  53.89355798309251\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  52.97145530965228\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  52.0679217183432\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  51.18257900256935\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  50.3150568258476\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  49.4649925515781\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  48.63203107674104\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  47.81582466942097\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  47.01603281006116\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  46.232322036355264\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  45.46436579168372\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  44.711844277007124\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  43.97444430612975\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  43.25185916425003\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  42.543788469715665\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  41.849938038904725\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  41.170019754155895\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  40.503751434671926\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  39.85085671032467\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  39.21106489828997\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  38.58411088244383\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  37.96973499545261\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  37.367682903492025\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  36.7777054935318\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  36.1995587631234\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  35.63300371263166\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  35.07780623985096\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  34.5337370369495\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  34.00057148968592\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  33.47808957884444\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  32.96607578383575\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  32.4643189884129\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  31.972612388451463\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  31.490753401746574\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  31.018543579778548\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  30.555788521401382\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  30.10229778840952\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  29.657884822938755\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  29.222366866658835\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  28.79556488171617\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  28.377303473386476\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  27.967410814397528\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  27.56571857088374\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  27.172061829935327\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  26.786279028705227\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  26.408211885038334\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  26.037705329588352\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  25.67460743938823\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  25.31876937284155\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  24.97004530610236\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  24.628292370812094\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  24.293370593163075\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  23.965142834258756\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  23.643474731741488\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  23.328234642659368\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  23.019293587544553\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  22.71652519567574\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  22.41980565149883\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  22.129013642179757\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  21.844030306264067\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  21.564739183419274\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  21.291026165235678\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  21.022779447062394\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  20.759889480855662\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  20.50224892901726\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  20.249752619201224\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  20.002297500067694\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  19.75978259796307\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  19.52210897450621\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  19.289179685061036\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  19.060899738076056\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  18.837176055272145\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  18.617917432659976\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  18.403034502369117\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  18.19243969527143\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  17.986047204381293\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  17.78377294901613\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  17.58553453970074\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  17.39125124379935\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  17.20084395185995\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  17.014235144655224\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  16.83134886090588\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  16.652110665670715\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  16.47644761939019\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  16.304288247568845\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  16.135562511083375\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  15.970201777102647\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  15.80813879060703\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  15.649307646493993\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  15.493643762257593\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  15.34108385123002\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  15.191565896372678\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  15.045029124605684\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  14.90141398166435\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  14.760662107471138\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  14.622716312012825\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  14.487520551711583\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  14.355019906280248\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  14.225160556050987\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  14.09788975976792\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  13.973155832833568\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  13.850908126000022\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  13.731097004495055\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  13.613673827574496\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  13.498590928491797\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  13.385801594875913\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  13.275260049509376\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  13.16692143149782\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  13.060741777823015\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  12.95667800527147\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  12.854687892730643\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  12.754730063845193\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  12.656763970025926\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  12.560749873803902\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  12.46664883252261\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  12.37442268236151\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  12.284034022683494\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  12.19544620070019\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  12.108623296448151\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  12.02353010806959\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  11.940132137391517\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  11.858395575796905\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  11.778287290382133\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  11.699774810394457\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  11.622826313944241\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  11.547410614985694\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  11.473497150561238\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  11.401055968303476\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  11.330057714190028\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  11.26047362054555\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  11.192275494286312\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  11.125435705402051\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  11.059927175670387\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  10.995723367598963\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  10.93279827359075\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  10.871126405327901\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  10.810682783369671\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  10.75144292696\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  10.693382844040569\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  10.636479021465181\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  10.580708415411097\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  10.526048441983628\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  10.472476968009907\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  10.41997230201789\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  10.368513185397022\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  10.318078783736707\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  10.268648678339042\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  10.22020285790229\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  10.172721710371528\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  10.12618601495319\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  10.080576934290104\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  10.03587600679373\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.99206513913058\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.949126598859483\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.907043007216775\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.86579733204632\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.825372880871583\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.785753294106689\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.74692253840375\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.708864900133728\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.671564978998095\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.635007681768636\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.59917821615276\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.564062084781986\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.52964507932079\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.495913274693743\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.462853023428167\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.430450950110396\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.398693945952948\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.36756916347062\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.337064011263314\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.307166148903251\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.277863481924664\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.249144156913804\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.220996556697283\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.193409295626724\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.166371214957802\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.139871378321851\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.113899067287997\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.088443777014158\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.06349521198512\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.039043281835761\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  9.015078097257932\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.991589965989142\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.96856938888158\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.946007056049602\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.923893843094397\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.902220807404072\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.880979184527696\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.86016038462188\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.839755988968369\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.819757746561237\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.800157570762275\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.780947536023241\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.762119874673605\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.743666973772461\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.725581372023381\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.707855756750849\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.690482960937114\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.673455960318234\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.656767870538129\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.640411944359466\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.624381568930211\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.608670263104859\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.59327167481903\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.578179578516545\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.563387872627926\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.54889057709911\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.5346818309696\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.520755889998908\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.507107124340394\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.493730016261484\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.480619157909498\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.467769249121922\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.455175095280493\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.442831605208049\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.430733789107318\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.418876756540891\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.407255714451487\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.395865965221667\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.384702904772293\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.37376202069891\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.36303889044531\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.352529179513498\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.342228639709381\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.332133107423473\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.322238501945826\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.312540823814615\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.303036153197624\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.293720648306039\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.284590543839819\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.275642149464142\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.266871848316137\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.258276095541463\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.249851416860022\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.241594407160283\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.233501729121619\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.225570111864132\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.217796349625333\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.21017730046328\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.2027098849855\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.195391085103276\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.188217942810766\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.181187558988446\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.174297092230386\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.167543757694936\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.160924825978276\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.154437622010422\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.148079523973276\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.141847962240185\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.135740418336626\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.12975442392166\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.123887559789603\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.11813745489166\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.11250178537702\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.106978273653034\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.10156468746417\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.096258838989256\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.091058583956782\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.085961820777749\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.080966489695848\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.076070571954572\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.071272088980841\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.06656910158502\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.06195970917673\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.05744204899641\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.05301429536209\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.048674658931207\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.044421385977131\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.040252757680092\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.036167089432205\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.032162730156392\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.028238061638817\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.024391497874658\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.020621484426862\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.016926497797712\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.013305044812896\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.00975566201784\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.006276915086065\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  8.002867398239315\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.999525733679273\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.996250571030539\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.993040586794717\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.98989448381542\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.986810990753858\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.983788861574927\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.980826875043474\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.977923834230653\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.975078566030077\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.972289920683596\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.969556771316543\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.966878013482221\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.964252564715464\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.9616793640950645\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.959157371814974\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.956685568763952\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.954262956113673\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.951888554914964\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.949561405702128\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.947280568105127\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.945045120469488\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.9428541594837645\n","error shape :  (551, 1)\n","After error * self.X  Shape :  (551, 1)\n","Loss :  7.940706799814447\n"]},{"output_type":"execute_result","data":{"text/plain":["{'weights': array([28.94658446]), 'bias': 49.16940274610614}"]},"metadata":{},"execution_count":103}]}]}